# -*- coding: utf-8 -*-
"""Instargram Hashtag Crawling.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UB9Dv5qenFsVSGTGVLW7fthYmZIKOB5J
"""

# Import Library
import selenium
from selenium import webdriver
from bs4 import BeautifulSoup
import time
import sys
from selenium.webdriver.common.keys import Keys
import urllib.request as req
import requests

################################
##### 0. 크롬드라이버 실행 #####
################################
driver = webdriver.Chrome(r'C:\Users\User\Desktop\Python\Crawling/chromedriver.exe')

################################
##### 1. 인스타그램 로그인 ##### 
################################

#### 1) 아이디 비밀번호 설정
username = " 인스타그램 아이디 "
userpw = " 인스타그램 비밀번호 "

#### 2) 로그인
log_in_url = 'https://www.instagram.com/accounts/login/'
driver.get(log_in_url)
time.sleep(5)
driver.find_element_by_name('username').send_keys(username)
driver.find_element_by_name('password').send_keys(userpw)

driver.find_element_by_css_selector('button.sqdOP.L3NKy.y3zKF').click()
time.sleep(5)

##################################
##### 2. 인스타그램 검색하기 #####
##################################
#### 1) 검색어 설정
search = '경대맛집'

#### 2) 검색할 게시물 최소값 설정
number_of_link = 20

#### 3) 인스타그램 검색
url = 'http://www.instagram.com/explore/tags/'+search+'/'
driver.get(url)
time.sleep(5)

#### 4) 총 게시물 개수 구하기
pageString = driver.page_source
bsObj = BeautifulSoup(pageString, "html.parser")
n= bsObj.find(name = 'span', attrs = { "class" : "g47SY"}).text

N = int(n.replace(',', ''))

#### 5) 게시물 링크 구하기
act = True # 반복 or 정지 기준

link_list = [] # 게시물 링크가 저장될 리스트
elem = driver.find_element_by_tag_name('body')

while act :
    pageString = driver.page_source 
    bsObj = BeautifulSoup(pageString, "html.parser")
    link = bsObj.find_all(name = 'div', attrs = { "class" : "Nnq7C weEfm"}) # 해당 클래스는 3개의 게시물이 하나의 줄로 묶여있음
    
    # 묶여있는 3개의 게시물에서 각각의 게시물의 링크를 저장하기
    for link1 in link : 
        for i in range(3) :    
            tmp = link1.select('a')[i]
            link_list.append(tmp.attrs['href'])
    
    # 페이지 다운을 클릭해서 스크롤 내리기
    for j in range(4) :
        elem.send_keys(Keys.PAGE_DOWN)
    
    # set을 통해 중복 링크 삭제
    link_list = list(set(link_list))
 

    # 정지 조건
    # (1) 설정한 최소 개수 보다 많아지면 정지
    if  len(link_list) > number_of_link :
        act = False
    # (2) 모든 게시물의 링크를 얻었으면 정지
    if len(link_list) == N :
        act = False
        
#### 6) 해쉬태그 크롤링하기
hashtag = [] # 해쉬태그가 저장될 리스트

# 5)에서 구한 링크에 대해서 크롤링
for x in link_list : 
    word_list = []
    
    # 하나의 링크에 대해 정보 가져오기
    url = 'https://www.instagram.com' + x
    res = requests.get(url)
    data = BeautifulSoup(res.content, "html.parser")
    
    # 해쉬태그 크롤링
    tmp = data.find_all(attrs = { "property" : "instapp:hashtags"})
    for y in tmp :
        word_list.append(y['content'])
    
    # 댓글에 달린 해쉬태그 크롤링
    tmp = data.find_all(attrs = { "property" : "video:tag"})
    for y in tmp :
        word_list.append(y['content'])
    
    # 하나의 링크에서 얻은 해쉬태그 리스트를 다시 리스트에 저장
    hashtag.append(word_list)
    
#### 7) 요약
print("총 게시물 개수 : "+n)
print("추출한 게시물의 개수 : " + str(len(link_list)))











